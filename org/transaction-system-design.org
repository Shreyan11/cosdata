#+TITLE: Cosdata Transaction System Design
#+AUTHOR: Nithin Mani
#+DATE: 2025-06-06
#+DESCRIPTION: Formal design document for explicit and implicit transaction systems in Cosdata

* Overview

Cosdata implements a dual-transaction architecture designed to address two fundamentally different data ingestion patterns while maintaining strict append-only semantics and monotonic version control. The system recognizes that modern applications require both atomic batch processing capabilities for large corpus imports and real-time streaming data ingestion with immediate searchability. To meet these diverse requirements, Cosdata provides explicit transactions for controlled, atomic operations and implicit transactions for high-throughput streaming scenarios.

The architecture maintains the core principle that all data modifications result in new versions rather than in-place updates, ensuring complete historical immutability and enabling time-travel queries across any point in the database's evolution. Both transaction types contribute to a single, linearly ordered version history using monotonically increasing version numbers, eliminating the complexity of branching version trees while preserving full auditability.

* Explicit Transactions

** Conceptual Foundation

Explicit transactions serve applications that need to import logically cohesive datasets as atomic units. This transaction model is particularly valuable when dealing with large corpora for vector semantic search or full-text indexing where partial imports would compromise the logical integrity of the dataset. The explicit transaction ensures that either all records in a corpus are successfully indexed and made available, or none are, providing strong consistency guarantees.

The design philosophy behind explicit transactions recognizes that importing large datasets is fundamentally different from real-time data streaming. Large imports benefit from batch processing optimizations, can tolerate longer processing times, and require clear success or failure semantics. Users importing research papers, product catalogs, or knowledge bases need confidence that their entire dataset is consistently available for querying once the import process completes.

** Transaction Lifecycle and Resource Management

Explicit transactions follow the resource-based REST API pattern described in the transactions.org specification, treating each transaction as a first-class resource with its own lifecycle. When a client initiates an explicit transaction, the system creates a new transaction resource identified by a unique hash / string. This identifier serves as the primary key for all subsequent operations within the transaction scope.

The transaction begins in an open state where it accepts data operations but performs no indexing. All upsert, update, and delete operations are buffered within the transaction context and written to a dedicated Write-Ahead Log (WAL) file. This buffering approach allows the system to optimize the eventual indexing process by analyzing the complete dataset before beginning index construction, potentially identifying opportunities for batch optimizations and conflict resolution.

During the data accumulation phase, clients can perform multiple operations against the transaction using RESTful endpoints that include the transaction identifier. The system validates each operation and buffers the changes while maintaining detailed logs for recovery purposes. The transaction remains in this state until the client explicitly issues a commit command, at which point the system transitions to the indexing phase.

** Asynchronous Indexing Process

Upon receiving a commit command, the explicit transaction system begins its most distinctive feature: asynchronous batch indexing. Rather than processing records incrementally, the system analyzes the entire buffered dataset and begins constructing the necessary indexes in a single, coordinated operation. This approach allows for significant optimizations, including bulk index construction algorithms and memory-efficient processing patterns that would be impossible with incremental updates.

The asynchronous nature of this process acknowledges that large corpus imports are inherently time-consuming operations. Rather than blocking the client connection during indexing, the system immediately acknowledges the commit request and begins background processing. The client can then monitor progress through dedicated status endpoints that provide detailed information about the indexing operation's progress.

During the indexing phase, the system assigns a single version number to represent the entire corpus being imported. This version number is monotonically incremented from the previous highest version in the system, ensuring that the new corpus appears atomically in the version history. All records within the transaction share this version number, creating a clear logical grouping that simplifies historical queries and audit operations.

** Progress Monitoring and Observability

The explicit transaction system provides comprehensive observability into the indexing process through detailed status APIs. These endpoints expose real-time metrics including the percentage of records processed, current processing rate, estimated completion time, and overall transaction state. This level of detail enables clients to provide meaningful progress updates to end users and make informed decisions about system resource allocation.

The status information evolves through several distinct phases. Initially, transactions report a "not_started" status while queued for processing. Once indexing begins, the status transitions to "indexing_in_progress" with detailed progress metrics updated continuously. The system calculates processing rates and time estimates based on recent performance, providing accurate predictions for completion times. Upon successful completion, the transaction reports a "complete" status with summary statistics including total processing time and average throughput rates.

This observability extends beyond individual transactions to provide system-wide visibility into transaction queues and resource utilization. Administrators can monitor the number of pending transactions, system performance metrics, and resource consumption patterns to optimize system configuration and capacity planning.

** Concurrency Model and Resource Protection

Cosdata's explicit transaction concurrency model implements a sophisticated queue-based architecture that separates client interaction phases from background processing phases. The system enforces strict sequential ordering for client-facing transaction flows while enabling parallel execution of the background indexing pipeline.

From the client perspective, explicit transactions must follow a strictly sequential pattern where each transaction completes its entire open-upsert-commit flow before the next transaction can begin. This sequential constraint ensures predictable resource allocation during the data ingestion phase and prevents conflicts between concurrent transaction creations. Clients attempting to create overlapping explicit transactions will receive appropriate error responses, maintaining clear transaction boundaries and preventing partial state corruption.

However, the system's architecture enables a more sophisticated execution model behind this sequential interface. Once a client commits an explicit transaction, that transaction enters a background indexing queue where it can be processed independently of new client transaction flows. This separation allows new client transactions to begin their open-upsert-commit cycles while previously committed transactions undergo asynchronous indexing in the background.

The background indexing pipeline processes committed transactions sequentially, ensuring that version numbers are assigned in the correct order and that resource utilization remains predictable. Each transaction in the indexing queue receives dedicated system resources during its processing window, but the queue itself can accumulate multiple pending transactions, creating a pipeline effect that improves overall system throughput.

#+BEGIN_EXAMPLE
Time → 

Client Transaction Flow (Sequential):
T1: [O]→[U]→[C] 
T2:            [O]→[U]→[C] 
T3:                       [O]→[U]→[C]
T4:                                  [O]→[U]→[C]

Background Indexing Pipeline (Sequential but Independent):
                ┌──────────┐
T1:             │ Indexing │→[Complete]
                └──────────┘
T2:                         ┌──────────┐
                            │ Indexing │→[Complete]
                            └──────────┘
T3:                                     ┌──────────┐
                                        │ Indexing │→[Complete]
                                        └──────────┘

Legend:
[O]→[U]→[C] :=> [Open]→[Upsert]→[Commit] 
#+END_EXAMPLE

This architecture provides several important benefits. Clients experience predictable transaction semantics with clear success or failure boundaries, while the system maximizes resource utilization by overlapping client interaction phases with background processing phases. The sequential processing of background indexing ensures that version numbers remain properly ordered while the pipeline approach prevents client operations from being blocked by lengthy indexing operations.

The queue-based design also provides natural backpressure mechanisms. If the background indexing pipeline becomes saturated, the system can implement flow control by delaying acceptance of new transaction commits until sufficient queue capacity becomes available. This approach ensures that the system remains stable under high load while providing clear feedback to clients about system capacity constraints.

* Implicit Transactions

** Design Philosophy and Use Cases

Implicit transactions represent a fundamentally different approach to data ingestion, optimized for streaming scenarios where individual records must become immediately searchable upon insertion. This transaction model serves applications like real-time monitoring systems, live content feeds, and streaming analytics where the value of data diminishes rapidly if not immediately accessible.

The implicit transaction design recognizes that streaming data ingestion has different requirements than batch imports. Individual records are typically small, arrive at irregular intervals, and must be processed with minimal latency. Creating explicit transactions for each record would introduce unnecessary overhead and create excessive noise in the version history, making historical analysis more difficult and consuming system resources inefficiently.

Rather than requiring clients to manage transaction boundaries, implicit transactions automatically handle the complexity of batching records for efficient processing while maintaining the immediate availability that streaming applications require. This approach abstracts away the transactional complexity while preserving the system's append-only semantics and version control capabilities.

** Immediate Indexing and Availability

The implicit transaction system prioritizes data availability above all other concerns. When a client submits a record to the =/synctxn/upsert= endpoint, the system immediately writes the record to its dedicated Write-Ahead Log and performs in-memory indexing. By the time the client receives a 200 OK response, the record is fully searchable through all relevant indexes, including vector similarity search, full-text search, and any configured sparse indexes.

This immediate availability is achieved through careful separation of durability and persistence concerns. The WAL write ensures that the record is durable and will survive system failures, while the in-memory indexing ensures immediate searchability. The separation of these concerns allows the system to optimize each independently, providing both strong durability guarantees and minimal latency.

The in-memory indexing process updates all relevant data structures immediately, ensuring that subsequent queries will include the newly inserted records. This includes updating vector indexes for similarity search, text indexes for full-text search, and any key-value mappings required for efficient retrieval. The system maintains these in-memory structures with the same consistency guarantees as persistent indexes, ensuring that immediate searches return accurate and complete results.

** Epoch-Based WAL Management

Implicit transactions utilize a sophisticated epoch-based Write-Ahead Log system that balances durability requirements with efficient resource utilization. Unlike explicit transactions that maintain individual WAL files, implicit transactions share a common WAL that is organized into epochs representing distinct time periods or record count thresholds.

The epoch-based approach allows the system to batch WAL writes efficiently while maintaining strict ordering guarantees. Records within an epoch are guaranteed to be written in the order they were received, but the system can optimize disk I/O by batching multiple records into single write operations. This batching significantly improves throughput for high-volume streaming scenarios while preserving the ordering information necessary for recovery operations.

Each epoch represents a logical boundary for serialization operations. When the system determines that an epoch should be serialized to persistent storage, all records within that epoch are processed together and assigned a single version number. This batching approach reduces the total number of versions created while ensuring that related records that arrived within similar timeframes are logically grouped together in the version history.

** Periodic Serialization and Version Creation

The implicit transaction system implements a sophisticated periodic serialization mechanism that balances the need for persistent storage with system performance. Rather than immediately persisting every record to disk, the system accumulates records in memory and periodically serializes batches to create new persistent versions.

The serialization process considers multiple factors when determining when to create a new version. Time-based triggers ensure that records don't remain in memory indefinitely, while volume-based triggers prevent memory exhaustion during high-throughput periods. The system also monitors query patterns and can trigger early serialization if it detects that historical queries are frequently accessing recent but not-yet-serialized data.

During serialization, the system creates comprehensive persistent indexes from the accumulated in-memory structures. This process involves writing updated vector indexes, text indexes, and metadata structures to disk while maintaining strict consistency with the existing version history. The new version receives a monotonically increasing version number and becomes available for historical queries once the serialization process completes.

The serialization process is designed to be non-blocking for ongoing data ingestion. New records continue to be accepted and indexed in memory while previous epochs are being serialized, ensuring that the system maintains consistent throughput regardless of serialization activity.

** Interaction with Explicit Transactions

The interaction between implicit and explicit transactions represents one of the most sophisticated aspects of Cosdata's transaction architecture. The system must coordinate between these two transaction types while maintaining strict ordering guarantees and ensuring that explicit transactions receive priority for resource allocation.

When an explicit transaction is initiated while implicit transactions are ongoing, the system implements a prioritization mechanism that ensures the explicit transaction can proceed without interference. This involves serializing any pending implicit transaction epochs to clear memory and computational resources for the explicit transaction's exclusive use. The serialization process for these interrupted epochs follows the same consistency guarantees as normal periodic serialization, ensuring no data loss or corruption.

During explicit transaction processing, implicit transactions can continue to accept new records and perform in-memory indexing. However, their serialization is deferred until the explicit transaction completes. This approach ensures that the explicit transaction receives full system resources while maintaining the immediate availability guarantees that implicit transactions provide.

The coordination between transaction types also extends to version number assignment. The system maintains a global version counter that both transaction types increment, ensuring that version numbers remain strictly ordered regardless of which transaction type created them. This unified versioning approach simplifies historical queries and maintains the system's append-only semantics across all transaction types.

* Version Management and Historical Consistency

** Unified Version Control Architecture

Cosdata's transaction system implements a unified version control architecture that treats all data modifications, regardless of transaction type, as contributions to a single, linear version history. This approach eliminates the complexity of parallel version streams while ensuring that historical queries can access any point in the database's evolution with complete consistency.

The version numbering system uses simple, monotonically increasing 32-bit integers that provide a total ordering of all changes in the system. This simplification from the previous hash-based versioning system improves performance and reduces memory overhead while maintaining all necessary functionality for historical queries and audit operations.

Each version represents a complete, immutable snapshot of the database at a specific point in time. Explicit transactions create versions that represent entire corpus imports, while implicit transactions create versions that represent batches of streaming records. Despite these different granularities, all versions participate in the same linear ordering, ensuring consistent semantics for historical operations.

** Ordering Guarantees and Consistency

The system provides specific ordering guarantees that balance performance with consistency requirements. Within individual transactions, records are not guaranteed to maintain strict insertion order, allowing the system to optimize indexing operations for better performance. However, version numbers are strictly ordered across all transaction types, ensuring that the overall evolution of the database follows a predictable sequence.

This ordering model reflects the reality that most applications care more about the logical consistency of dataset versions than about the specific ordering of individual records within those versions. By relaxing intra-transaction ordering requirements, the system can parallelize indexing operations and apply various optimization techniques that significantly improve throughput.

The append-only nature of the version system ensures that once a version is created, it never changes. This immutability guarantee enables the system to cache version data aggressively and provide strong consistency guarantees for historical queries. Applications can depend on the fact that querying the same version at different times will always return identical results, regardless of subsequent database modifications.

* Integration with Context-Based Querying

The transaction system integrates seamlessly with Cosdata's context-based versioning system to provide powerful historical query capabilities. Each committed transaction, whether explicit or implicit, creates new version contexts that can be accessed independently through the context API.

This integration allows applications to perform sophisticated temporal queries, comparing results across different versions or analyzing the evolution of data over time. The combination of the transaction system's version creation with the context system's query isolation provides a powerful foundation for applications that require audit trails, temporal analysis, or reproducible research results.

The context system's lightweight, immutable snapshots complement the transaction system's append-only architecture, ensuring that historical queries do not interfere with ongoing data ingestion operations. This separation of concerns allows the system to optimize each component independently while maintaining strong consistency guarantees across the entire architecture.

* Conclusion

Cosdata's dual-transaction architecture represents a sophisticated approach to balancing the competing demands of atomic batch processing and real-time streaming data ingestion. By implementing explicit transactions for controlled, atomic operations and implicit transactions for immediate data availability, the system serves a broad range of application requirements while maintaining strict consistency and historical integrity.

The careful coordination between these transaction types, combined with the unified version control system and context-based querying capabilities, creates a powerful platform for applications that require both real-time responsiveness and historical analysis capabilities. This architecture positions Cosdata to serve as a foundation for next-generation applications that demand both immediate data availability and comprehensive historical access.
